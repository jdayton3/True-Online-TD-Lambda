{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tiles3 import tiles, IHT  # This is the package for constructing the feature tilings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selector(actions, values, epsilon):\n",
    "    greedy = np.random.choice([1,0], p=[1-epsilon, epsilon])\n",
    "    if greedy:\n",
    "        return actions[np.argmax(values)]\n",
    "    else:\n",
    "        return np.random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_episodes = 100\n",
    "n_timesteps = 1500\n",
    "n_tilings = 10\n",
    "tiling_dim = 10\n",
    "max_tile_size = 800 # ?? how to pick\n",
    "iht = IHT(max_tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env._max_episode_steps = n_timesteps\n",
    "n_action = env.action_space.n\n",
    "obs_highs = env.observation_space.high\n",
    "obs_lows = env.observation_space.low\n",
    "scales = [tiling_dim / (obs_highs[i] - obs_lows[i]) for i in range(len(obs_highs))]\n",
    "\n",
    "# theta = np.zeros(max_tile_size + env.action_space.n)  # last n spots indicate which action\n",
    "theta = np.zeros(max_tile_size *  3)\n",
    "\n",
    "# Tiling helper function\n",
    "# Because the tiles code only divides at integers, we must scale our observations to tiling_dim x tiling_dim space\n",
    "def mytiles(pt, a):\n",
    "    pt_ = np.array([p*scales[i] for i,p in enumerate(list(pt))])\n",
    "    features = list(np.array(tiles(iht, n_tilings, pt_)) + a * max_tile_size)\n",
    "    phi = np.zeros_like(theta)\n",
    "    phi[features] = 1\n",
    "    return phi\n",
    "\n",
    "# init weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1089 timesteps\n",
      "Episode finished after 1464 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1060 timesteps\n",
      "Episode finished after 1155 timesteps\n",
      "Episode finished after 1257 timesteps\n",
      "Episode finished after 868 timesteps\n",
      "Episode finished after 676 timesteps\n",
      "Episode finished after 572 timesteps\n",
      "Episode finished after 1095 timesteps\n",
      "Episode finished after 775 timesteps\n",
      "Episode finished after 858 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 475 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 796 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 676 timesteps\n",
      "Episode finished after 789 timesteps\n",
      "Episode finished after 1135 timesteps\n",
      "Episode finished after 638 timesteps\n",
      "Episode finished after 1333 timesteps\n",
      "Episode finished after 349 timesteps\n",
      "Episode finished after 1122 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1326 timesteps\n",
      "Episode finished after 550 timesteps\n",
      "Episode finished after 579 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 773 timesteps\n",
      "Episode finished after 880 timesteps\n",
      "Episode finished after 1292 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1355 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 938 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1064 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1225 timesteps\n",
      "Episode finished after 351 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 556 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n",
      "Episode finished after 1500 timesteps\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "epsilon = .5 # (greedy)\n",
    "gamma = .9\n",
    "lam = .9\n",
    "alpha = 1. / (10 * n_tilings) # alpha is often 1/10n where n is number of tilings\n",
    "actions = range(env.action_space.n)\n",
    "\n",
    "for i_episode in range(n_episodes):\n",
    "    epsilon *= .95\n",
    "    epsilon = max(epsilon, .1)\n",
    "    observation = env.reset()\n",
    "    \n",
    "    \n",
    "#     phi_sa[-(n_action - action)] = 1  # turn on action feature\n",
    "    phis = [mytiles(observation, a) for a in actions] # get features for observation\n",
    "    q_vals = [theta.dot(phi) for phi in phis]\n",
    "    action = selector(actions, q_vals, epsilon)\n",
    "    phi_sa = phis[action]\n",
    "    q_sa = q_vals[action]\n",
    "\n",
    "    # initialize e = 0\n",
    "    e = np.zeros_like(theta)\n",
    "    \n",
    "    for t in range(n_timesteps):\n",
    "#         env.render()\n",
    "        \n",
    "        # Take action, observe change, choose new a, get new features and q_sa_ and do update\n",
    "        \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        phis = [mytiles(observation, a) for a in actions]\n",
    "        q_vals = [theta.dot(phi) for phi in phis]\n",
    "        action = selector(actions, q_vals, epsilon)\n",
    "        phi_sa_ = phis[action]\n",
    "        q_sa_ = q_vals[action]\n",
    "        \n",
    "        \n",
    "        d = reward + gamma * q_sa_ - q_sa\n",
    "        e = gamma * lam * e + alpha * (1 - gamma * lam * e.dot(phi_sa)) * phi_sa\n",
    "        theta = theta + d * e + alpha * (q_sa - theta.dot(phi_sa)) * phi_sa\n",
    "        \n",
    "        \n",
    "        q_sa = q_sa_\n",
    "        phi_sa = phi_sa_\n",
    "    \n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = [0,1,2]\n",
    "values = [10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector(actions, values, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# three separate theta vectors ? one per action? noooo\n",
    "# include as nother dimension in tiling?\n",
    "# one theta, three times as long, each phi *= action*max_state_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
